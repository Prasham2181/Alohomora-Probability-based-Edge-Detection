<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Probabilistic Boundary Detection and Improving Convolutional Networks</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      margin: 20px;
      line-height: 1.6;
    }
    h1, h2, h3, h4 {
      color: #333;
    }
    pre {
      background-color: #f4f4f4;
      padding: 10px;
      border: 1px solid #ddd;
      overflow-x: auto;
    }
    table {
      border-collapse: collapse;
      width: 100%;
      margin: 20px 0;
    }
    table, th, td {
      border: 1px solid #ddd;
    }
    th, td {
      padding: 8px;
      text-align: center;
    }
    img {
      max-width: 100%;
      height: auto;
    }
    .center {
      text-align: center;
    }
  </style>
</head>
<body>
  <h1>Probabilistic Boundary Detection and Improving Convolutional Networks</h1>
  <h3><em>RBE549: Computer Vision - <a href="https://www.wpi.edu/">Worcester Polytechnic Institute</a>, Spring 2025</em></h3>

  <hr>

  <h2>Project Guidelines:</h2>
  <p>
    The project is divided into two phases. The first phase is to implement a probabilistic boundary detection algorithm. The second phase is to implement and improve the performance of the convolutional backbones using different techniques.
    Details of the project can be found <a href="https://rbe549.github.io/spring2025/hw/hw0/">here</a>.
  </p>

  <hr>

  <h2>Phase 1: Shake My Boundary</h2>
  <h3>Overview:</h3>
  <p>
    Phase 1 of the project involves the creation of various filter banks and their application to images for texture, brightness, and color analysis. The primary goal is to generate different maps and gradients that will be used to create a probabilistic boundary detection algorithm.
  </p>

  <h4>Steps to run the code:</h4>
  <p>To run the PBLite boundary detection, use the following command:</p>
  <pre>python Wrapper.py</pre>
  <p><em>Wrapper.py</em> reads input images from the <strong>BSDS500</strong> folder (or <strong>Images</strong> folder, as applicable) and all the outputs are stored in the <strong>Outputs</strong> folder.</p>

  <h4>Input:</h4>
  <p><strong>Original Image:</strong></p>
  <div class="center">
    <img src="Images/originalimage_1.jpg" alt="Original Image" style="width: 250px;">
  </div>

  <h4>Outputs:</h4>
  <p>Following are the outputs generated by the code:</p>

  <h4>Image Maps:</h4>
  <div class="center">
    <table>
      <tr>
        <td><img src="media/phase1_imgs/TextonMap_1.png" alt="Texton Map" style="width: 250px;"></td>
        <td><img src="media/phase1_imgs/BrightnessMap_1.png" alt="Brightness Map" style="width: 250px;"></td>
        <td><img src="media/phase1_imgs/ColorMap_1.png" alt="Color Map" style="width: 250px;"></td>
      </tr>
      <tr>
        <td>Texton Map</td>
        <td>Brightness Map</td>
        <td>Color Map</td>
      </tr>
    </table>
  </div>

  <h4>Image Gradients:</h4>
  <div class="center">
    <table>
      <tr>
        <td><img src="media/phase1_imgs/TextonGradient_1.png" alt="Texton Gradient" style="width: 250px;"></td>
        <td><img src="media/phase1_imgs/BrightnessGradient_1.png" alt="Brightness Gradient" style="width: 250px;"></td>
        <td><img src="media/phase1_imgs/ColorGradient_1.png" alt="Color Gradient" style="width: 250px;"></td>
      </tr>
      <tr>
        <td>Texton Gradient</td>
        <td>Brightness Gradient</td>
        <td>Color Gradient</td>
      </tr>
    </table>
  </div>

  <h4>Boundary Detection:</h4>
  <div class="center">
    <table>
      <tr>
        <td><img src="media/phase1_imgs/canny_baseline_1.png" alt="Canny Baseline" style="width: 250px;"></td>
        <td><img src="media/phase1_imgs/sobel_1.png" alt="Sobel Baseline" style="width: 250px;"></td>
        <td><img src="media/phase1_imgs/PbLite_1.png" alt="PbLite Output" style="width: 250px;"></td>
      </tr>
      <tr>
        <td>Canny Baseline</td>
        <td>Sobel Baseline</td>
        <td>PbLite</td>
      </tr>
    </table>
  </div>

  <hr>

  <h2>Phase 2: Deep Dive on Deep Learning</h2>
  <h3>Overview:</h3>
  <p>
    Phase 2 of the project involves the implementation of different convolutional backbones and their performance comparison. The primary goal is to implement and improve the performance of the convolutional backbones.
  </p>

  <h4>Steps to run the code:</h4>
  <h5>Train the model:</h5>
  <pre>python Train.py --NumEpochs &lt;NUMBER_OF_EPOCHS&gt; --MiniBatchSize &lt;BATCH_SIZE&gt; --ModelType &lt;MODEL_TYPE&gt; --CustomLogs &lt;PATH_TO_CUSTOMLOGS&gt;</pre>
  <p>
    <strong>Usage:</strong><br>
    Train.py [-h] [--CheckPointPath CHECKPOINTPATH] [--NumEpochs NUMEPOCHS] [--DivTrain DIVTRAIN] [--MiniBatchSize MINIBATCHSIZE] [--LoadCheckPoint LOADCHECKPOINT] [--LogsPath LOGSPATH] [--ModelType MODELTYPE] [--CustomLogs CUSTOMLOGS]
  </p>
  <p><strong>Example:</strong></p>
  <pre>python Train.py --NumEpochs 50 --MiniBatchSize 32 --ModelType Baseline --CustomLogs ../Logs</pre>

  <h5>Test the model:</h5>
  <pre>python Test.py --ModelPath &lt;PATH_TO_CHECKPOINT&gt; --SelectTestSet False --ModelType Baseline</pre>
  <p>
    <strong>Usage:</strong><br>
    Test.py [-h] [--ModelPath MODELPATH] [--LabelsPath LABELSPATH] [--SelectTestSet SELECTTESTSET] [--ModelType MODELTYPE] [--ConfusionMatrixPath CONFUSIONMATRIXPATH]
  </p>
  <p><strong>Example:</strong></p>
  <pre>python Test.py --ModelPath ../Checkpoints_dense/ResNext_24model.ckpt --SelectTestSet False --ModelType Baseline</pre>

  <hr>

  <h2>Quick Start</h2>
  <h4>Phase 1:</h4>
  <ol>
    <li>Navigate to the <code>Phase1/Code/</code> directory.</li>
    <li>Run the wrapper script:
      <pre>python Wrapper.py</pre>
    </li>
  </ol>

  <h4>Phase 2:</h4>
  <ol>
    <li>Navigate to the <code>Phase2/Code/</code> directory.</li>
    <li>Train the model:
      <pre>python Train.py --NumEpochs 25 --MiniBatchSize 128</pre>
    </li>
    <li>Test the model:
      <pre>python Test.py --ModelPath ../Checkpoints_dense/ResNext_24model.ckpt</pre>
    </li>
  </ol>

  <hr>

  <h2>Showcase: Image Comparisons</h2>
  <p>
    Display the key images side by side for an effective comparison. The table below shows the <strong>Original Image</strong>, <strong>Canny Baseline</strong>, <strong>Sobel Baseline</strong>, <strong>Ground Truth</strong>, and the final <strong>PbLite</strong> output.
  </p>
  <div class="center">
    <table>
      <tr>
        <th>Original Image</th>
        <th>Canny Baseline</th>
        <th>Sobel Baseline</th>
        <th>Ground Truth</th>
        <th>PbLite Final Output</th>
      </tr>
      <tr>
        <td><img src="Images/originalimage_1.jpg" alt="Original Image" style="width: 250px;"></td>
        <td><img src="media/phase1_imgs/canny_baseline_1.png" alt="Canny Baseline" style="width: 250px;"></td>
        <td><img src="media/phase1_imgs/sobel_1.png" alt="Sobel Baseline" style="width: 250px;"></td>
        <td><img src="media/phase1_imgs/grnd_truth_1.png" alt="Ground Truth" style="width: 250px;"></td>
        <td><img src="media/phase1_imgs/PbLite_1.png" alt="PbLite Output" style="width: 250px;"></td>
      </tr>
    </table>
  </div>

  <hr>

  <h2>Additional Outputs</h2>
  <h4>Image Maps:</h4>
  <div class="center">
    <table>
      <tr>
        <td><img src="media/phase1_imgs/TextonMap_1.png" alt="Texton Map" style="width: 250px;"></td>
        <td><img src="media/phase1_imgs/BrightnessMap_1.png" alt="Brightness Map" style="width: 250px;"></td>
        <td><img src="media/phase1_imgs/ColorMap_1.png" alt="Color Map" style="width: 250px;"></td>
      </tr>
      <tr>
        <td>Texton Map</td>
        <td>Brightness Map</td>
        <td>Color Map</td>
      </tr>
    </table>
  </div>

  <h4>Image Gradients:</h4>
  <div class="center">
    <table>
      <tr>
        <td><img src="media/phase1_imgs/TextonGradient_1.png" alt="Texton Gradient" style="width: 250px;"></td>
        <td><img src="media/phase1_imgs/BrightnessGradient_1.png" alt="Brightness Gradient" style="width: 250px;"></td>
        <td><img src="media/phase1_imgs/ColorGradient_1.png" alt="Color Gradient" style="width: 250px;"></td>
      </tr>
      <tr>
        <td>Texton Gradient</td>
        <td>Brightness Gradient</td>
        <td>Color Gradient</td>
      </tr>
    </table>
  </div>

  <hr>

  <h2>Acknowledgments</h2>
  <p>
    This project is part of the RBE549: Computer Vision course at Worcester Polytechnic Institute (Spring 2025). For more details and project guidelines, please visit the <a href="https://rbe549.github.io/spring2025/hw/hw0/">project website</a>.
  </p>

  <h2>License</h2>
  <p>[Include your license information here if applicable.]</p>
</body>
</html>
